# Chain of Responsibility Visual Guide

## Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ProviderFactory                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  CreateChatClient(modelName)                                â”‚
â”‚         â”‚                                                   â”‚
â”‚         â–¼                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚         Provider Chain (Built at startup)        â”‚      â”‚
â”‚  â”‚                                                  â”‚      â”‚
â”‚  â”‚   [Azure] â†’ [OpenAI] â†’ [GitHub]                 â”‚      â”‚
â”‚  â”‚                                                  â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚         â”‚                                                   â”‚
â”‚         â–¼                                                   â”‚
â”‚  TryCreateChatClient(modelName)                             â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Request Flow

```
User Request: "Create client for 'llama-3.2'"
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ProviderFactory                      â”‚
â”‚   CreateChatClient("llama-3.2")        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â”œâ”€â–º Log: "ğŸ” Looking for provider to handle model: llama-3.2"
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Handler 1: AzureOpenAIProviderHandler â”‚
â”‚                                        â”‚
â”‚  CanHandleModel("llama-3.2")?          â”‚
â”‚    â”œâ”€â–º Check: Is endpoint configured?  â”‚
â”‚    â”‚     âœ“ Yes                          â”‚
â”‚    â”œâ”€â–º Check: Can deployment handle it?â”‚
â”‚    â”‚     âœ“ Yes (accepts all models)    â”‚
â”‚    â”‚                                    â”‚
â”‚    â””â”€â–º CreateChatClient()               â”‚
â”‚          â”œâ”€â–º Success! Return client     â”‚
â”‚          â””â”€â–º OR fail â†’ Pass to next     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â”‚ (If Azure fails/can't handle)
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Handler 2: OpenAIProviderHandler      â”‚
â”‚                                        â”‚
â”‚  CanHandleModel("llama-3.2")?          â”‚
â”‚    â”œâ”€â–º Check: Is API key configured?   â”‚
â”‚    â”‚     âœ“ Yes                          â”‚
â”‚    â”œâ”€â–º Check: Is model in known list?  â”‚
â”‚    â”‚     âœ— No (llama not in OpenAI)    â”‚
â”‚    â”‚                                    â”‚
â”‚    â””â”€â–º Cannot handle â†’ Pass to next    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Handler 3: GitHubModelsProviderHandlerâ”‚
â”‚                                        â”‚
â”‚  CanHandleModel("llama-3.2")?          â”‚
â”‚    â”œâ”€â–º Check: Is token configured?     â”‚
â”‚    â”‚     âœ“ Yes                          â”‚
â”‚    â”œâ”€â–º Check: Is model supported?      â”‚
â”‚    â”‚     âœ“ Yes (llama-3.2 in list)     â”‚
â”‚    â”‚                                    â”‚
â”‚    â””â”€â–º CreateChatClient()               â”‚
â”‚          â””â”€â–º âœ“ Success! Return client   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Return IChatClient to User            â”‚
â”‚  Log: "âœ“ Provider 'GitHubModels'       â”‚
â”‚        handling model: llama-3.2"      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Handler Decision Tree

```
                    CanHandleModel(model)?
                            â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚                       â”‚
              YES                      NO
                â”‚                       â”‚
                â–¼                       â–¼
        CreateChatClient()      Pass to Next Handler
                â”‚                       â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”               â”‚
        â”‚               â”‚               â”‚
     Success         Exception          â”‚
        â”‚               â”‚               â”‚
        â–¼               â–¼               â–¼
   Return Client  Try Next Handler  Next.TryCreate()
                        â”‚               â”‚
                        â”‚          (Recursive)
                        â”‚               â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                        All Failed?
                                â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                      â”‚
                   YES                     NO
                    â”‚                      â”‚
                    â–¼                      â–¼
            Throw Exception         Return Client
```

## Provider Model Support Matrix

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model           â”‚ Azure OpenAI â”‚  OpenAI  â”‚ GitHub Models â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ gpt-4o          â”‚      âœ“       â”‚    âœ“     â”‚      âœ“        â”‚
â”‚ gpt-4o-mini     â”‚      âœ“       â”‚    âœ“     â”‚      âœ“        â”‚
â”‚ gpt-3.5-turbo   â”‚      âœ“       â”‚    âœ“     â”‚      âœ“        â”‚
â”‚ o1-preview      â”‚      âœ“       â”‚    âœ“     â”‚      âœ“        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ llama-3.2       â”‚      âœ“*      â”‚    âœ—     â”‚      âœ“        â”‚
â”‚ phi-3.5         â”‚      âœ“*      â”‚    âœ—     â”‚      âœ“        â”‚
â”‚ mistral-large   â”‚      âœ“*      â”‚    âœ—     â”‚      âœ“        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

* Azure OpenAI accepts all models if configured (uses deployment)
âœ“ = Can handle if configured
âœ— = Cannot handle (not in supported models list)
```

## Configuration to Chain Mapping

```
Configuration:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ "providerChain": [                     â”‚
â”‚    "azureOpenAI",    â† First in chain  â”‚
â”‚    "openAI",         â† Second in chain â”‚
â”‚    "githubModels"    â† Last in chain   â”‚
â”‚ ]                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
Runtime Chain:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Azure       â”‚â”€â”€â”€â”€â–ºâ”‚ OpenAI  â”‚â”€â”€â”€â”€â–ºâ”‚ GitHub       â”‚â”€â”€â”€â”€â–º null
â”‚ OpenAI      â”‚     â”‚         â”‚     â”‚ Models       â”‚
â”‚ Handler     â”‚     â”‚ Handler â”‚     â”‚ Handler      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  _nextHandler       _nextHandler      _nextHandler
```

## Logging Output Example

```
Console Output:

ğŸ” Looking for provider to handle model: llama-3.2

  Trying: AzureOpenAIProviderHandler
    â”œâ”€ Configuration check: âœ“ Endpoint configured
    â”œâ”€ Configuration check: âœ“ Deployment configured  
    â””â”€ Model support: âœ“ Accepts all models
    â””â”€â–º âœ“ Provider 'AzureOpenAI' handling model: llama-3.2

âœ… Chat client created successfully!
```

```
Console Output (Fallback Scenario):

ğŸ” Looking for provider to handle model: llama-3.2

  Trying: AzureOpenAIProviderHandler
    â”œâ”€ Configuration check: âœ— Endpoint not configured
    â””â”€â–º Passing to next handler...

  Trying: OpenAIProviderHandler
    â”œâ”€ Configuration check: âœ“ API key configured
    â”œâ”€ Model support: âœ— llama-3.2 not in OpenAI catalog
    â””â”€â–º Passing to next handler...

  Trying: GitHubModelsProviderHandler
    â”œâ”€ Configuration check: âœ“ Token configured
    â”œâ”€ Model support: âœ“ llama-3.2 supported
    â””â”€â–º âœ“ Provider 'GitHubModels' handling model: llama-3.2

âœ… Chat client created successfully!
```

## Class Relationship Diagram

```
                  IProviderHandler (Interface)
                         â”‚
                         â”‚ implements
                         â–¼
               BaseProviderHandler (Abstract)
                         â”‚
                         â”‚ extends
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                â”‚                â”‚
        â–¼                â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Azure       â”‚  â”‚  OpenAI    â”‚  â”‚  GitHub      â”‚
â”‚ OpenAI      â”‚  â”‚  Provider  â”‚  â”‚  Models      â”‚
â”‚ Provider    â”‚  â”‚  Handler   â”‚  â”‚  Provider    â”‚
â”‚ Handler     â”‚  â”‚            â”‚  â”‚  Handler     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Each handler:
- Knows if it can handle a model
- Creates chat clients for supported models
- Passes requests to next handler if unable
```

---

**Visual Guide Created**: 2026-01-30  
**Pattern**: Chain of Responsibility

